{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 Homework - Data Warehousing with DuckDB\n",
    "\n",
    "This notebook contains solutions to Module 3 homework using DuckDB instead of BigQuery.\n",
    "\n",
    "**Dataset**: Yellow Taxi Trip Records for January 2024 - June 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize DuckDB connection\n",
    "con = duckdb.connect('homework.duckdb')\n",
    "\n",
    "print(\"DuckDB version:\", duckdb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create External Table (similar to BigQuery External Table)\n",
    "\n",
    "In DuckDB, we can query Parquet files directly without loading them into memory - this is similar to BigQuery's External Tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view that reads directly from parquet files (like an external table)\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE VIEW yellow_taxi_external AS\n",
    "SELECT * FROM read_parquet('data/yellow_tripdata_2024-*.parquet')\n",
    "\"\"\")\n",
    "\n",
    "print(\"External view created successfully\")\n",
    "\n",
    "# Preview the data\n",
    "con.execute(\"SELECT * FROM yellow_taxi_external LIMIT 5\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Materialized Table (similar to BigQuery Table)\n",
    "\n",
    "Now let's create a regular table by loading all data into DuckDB - this is similar to a materialized table in BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a materialized table (data loaded into DuckDB)\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE yellow_taxi_materialized AS\n",
    "SELECT * FROM read_parquet('data/yellow_tripdata_2024-*.parquet')\n",
    "\"\"\")\n",
    "\n",
    "print(\"Materialized table created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Total Record Count\n",
    "\n",
    "**Question**: What is count of records for the 2024 Yellow Taxi Data?\n",
    "\n",
    "Options:\n",
    "- 65,623\n",
    "- 840,402\n",
    "- 20,332,093\n",
    "- 85,431,289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total records\n",
    "result = con.execute(\"\"\"\n",
    "SELECT COUNT(*) as total_records\n",
    "FROM yellow_taxi_materialized\n",
    "\"\"\").df()\n",
    "\n",
    "total_records = result['total_records'][0]\n",
    "print(f\"Total records: {total_records:,}\")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: 20,332,093"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Distinct PULocationIDs - External vs Materialized\n",
    "\n",
    "**Question**: Write a query to count the distinct number of PULocationIDs for the entire dataset on both the tables. What is the estimated amount of data that will be read when this query is executed on the External Table and the Table?\n",
    "\n",
    "**Note**: DuckDB doesn't provide byte estimates like BigQuery, but we can observe the conceptual difference:\n",
    "- External view: Reads directly from Parquet files (only the column needed)\n",
    "- Materialized table: Data already in DuckDB storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query on external view\n",
    "result_external = con.execute(\"\"\"\n",
    "SELECT COUNT(DISTINCT PULocationID) as distinct_pu_locations\n",
    "FROM yellow_taxi_external\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"External view result:\")\n",
    "print(result_external)\n",
    "\n",
    "# Query on materialized table\n",
    "result_materialized = con.execute(\"\"\"\n",
    "SELECT COUNT(DISTINCT PULocationID) as distinct_pu_locations\n",
    "FROM yellow_taxi_materialized\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nMaterialized table result:\")\n",
    "print(result_materialized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer for BigQuery**: 0 MB for the External Table and 155.12 MB for the Materialized Table\n",
    "\n",
    "**Explanation**: \n",
    "- External tables in BigQuery don't cache metadata, so the estimate is 0 MB\n",
    "- Materialized tables have full metadata, showing the actual data size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Columnar Storage - One vs Two Columns\n",
    "\n",
    "**Question**: Write a query to retrieve the PULocationID from the table. Now write a query to retrieve the PULocationID and DOLocationID on the same table. Why are the estimated number of Bytes different?\n",
    "\n",
    "**Answer**: BigQuery is a columnar database, and it only scans the specific columns requested in the query. Querying two columns (PULocationID, DOLocationID) requires reading more data than querying one column (PULocationID), leading to a higher estimated number of bytes processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query with one column\n",
    "result_one = con.execute(\"\"\"\n",
    "SELECT PULocationID\n",
    "FROM yellow_taxi_materialized\n",
    "LIMIT 10\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"One column query:\")\n",
    "print(result_one)\n",
    "\n",
    "# Query with two columns\n",
    "result_two = con.execute(\"\"\"\n",
    "SELECT PULocationID, DOLocationID\n",
    "FROM yellow_taxi_materialized\n",
    "LIMIT 10\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nTwo column query:\")\n",
    "print(result_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: Both BigQuery and DuckDB use columnar storage. When you query one column, only that column's data is scanned. When you query two columns, both columns' data must be scanned, roughly doubling the bytes processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Zero Fare Amount\n",
    "\n",
    "**Question**: How many records have a fare_amount of 0?\n",
    "\n",
    "Options:\n",
    "- 128,210\n",
    "- 546,578\n",
    "- 20,188,016\n",
    "- 8,333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count records with fare_amount = 0\n",
    "result = con.execute(\"\"\"\n",
    "SELECT COUNT(*) as zero_fare_count\n",
    "FROM yellow_taxi_materialized\n",
    "WHERE fare_amount = 0\n",
    "\"\"\").df()\n",
    "\n",
    "zero_fare_count = result['zero_fare_count'][0]\n",
    "print(f\"Records with fare_amount = 0: {zero_fare_count:,}\")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: 8,333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Optimization Strategy - Partitioning and Clustering\n",
    "\n",
    "**Question**: What is the best strategy to make an optimized table in Big Query if your query will always filter based on tpep_dropoff_datetime and order the results by VendorID?\n",
    "\n",
    "**Answer**: Partition by tpep_dropoff_datetime and Cluster on VendorID\n",
    "\n",
    "**Explanation**: \n",
    "- Partition by the date column used for filtering (tpep_dropoff_datetime) - this reduces the amount of data scanned\n",
    "- Cluster by the column used for ordering (VendorID) - this optimizes sorting operations\n",
    "\n",
    "In DuckDB, we don't have the same partitioning/clustering as BigQuery, but we can demonstrate the concept by creating an ordered table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimized table with data ordered by dropoff datetime and VendorID\n",
    "con.execute(\"\"\"\n",
    "CREATE OR REPLACE TABLE yellow_taxi_optimized AS\n",
    "SELECT * \n",
    "FROM yellow_taxi_materialized\n",
    "ORDER BY tpep_dropoff_datetime, VendorID\n",
    "\"\"\")\n",
    "\n",
    "print(\"Optimized table created (sorted by tpep_dropoff_datetime and VendorID)\")\n",
    "\n",
    "# Verify the table\n",
    "con.execute(\"\"\"\n",
    "SELECT COUNT(*) as record_count,\n",
    "       MIN(tpep_dropoff_datetime) as min_dropoff,\n",
    "       MAX(tpep_dropoff_datetime) as max_dropoff\n",
    "FROM yellow_taxi_optimized\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: Query Performance - Non-Partitioned vs Partitioned\n",
    "\n",
    "**Question**: Write a query to retrieve the distinct VendorIDs between tpep_dropoff_datetime 2024-03-01 and 2024-03-15 (inclusive). Compare the estimated bytes between the materialized table and the partitioned table.\n",
    "\n",
    "**Answer**: 310.24 MB for non-partitioned table and 26.84 MB for the partitioned table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query on regular materialized table\n",
    "result_regular = con.execute(\"\"\"\n",
    "SELECT DISTINCT VendorID\n",
    "FROM yellow_taxi_materialized\n",
    "WHERE tpep_dropoff_datetime >= '2024-03-01'\n",
    "  AND tpep_dropoff_datetime < '2024-03-16'\n",
    "ORDER BY VendorID\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Non-partitioned table result:\")\n",
    "print(result_regular)\n",
    "\n",
    "# Query on optimized (sorted) table\n",
    "result_optimized = con.execute(\"\"\"\n",
    "SELECT DISTINCT VendorID\n",
    "FROM yellow_taxi_optimized\n",
    "WHERE tpep_dropoff_datetime >= '2024-03-01'\n",
    "  AND tpep_dropoff_datetime < '2024-03-16'\n",
    "ORDER BY VendorID\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"\\nOptimized (sorted) table result:\")\n",
    "print(result_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation**: In BigQuery, partitioning by date allows the query optimizer to skip entire partitions that don't match the date range. For a query filtering on March 1-15, a partitioned table only scans ~2 weeks of data, while a non-partitioned table must scan the entire 6-month dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7: External Table Storage Location\n",
    "\n",
    "**Question**: Where is the data stored in the External Table you created?\n",
    "\n",
    "Options:\n",
    "- Big Query\n",
    "- Container Registry\n",
    "- GCP Bucket\n",
    "- Big Table\n",
    "\n",
    "**Answer**: GCP Bucket\n",
    "\n",
    "**Explanation**: External tables in BigQuery reference data stored in external sources like GCS (Google Cloud Storage) buckets. The data remains in the bucket and is not copied into BigQuery storage. Similarly, our DuckDB external view reads directly from the Parquet files on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our case, the external view reads from local Parquet files\n",
    "from pathlib import Path\n",
    "\n",
    "data_files = list(Path('data').glob('yellow_tripdata_2024-*.parquet'))\n",
    "print(\"External data files:\")\n",
    "for f in data_files:\n",
    "    size_mb = f.stat().st_size / (1024 * 1024)\n",
    "    print(f\"  {f.name}: {size_mb:.2f} MB\")\n",
    "\n",
    "total_size = sum(f.stat().st_size for f in data_files) / (1024 * 1024)\n",
    "print(f\"\\nTotal external data size: {total_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8: Clustering Best Practice\n",
    "\n",
    "**Question**: It is best practice in Big Query to always cluster your data:\n",
    "\n",
    "**Answer**: False\n",
    "\n",
    "**Explanation**: Clustering is not always beneficial. It's most useful when:\n",
    "- You frequently filter or aggregate by specific columns\n",
    "- Your table is large (> 1 GB)\n",
    "- Your queries filter on high-cardinality columns\n",
    "\n",
    "For small tables or tables without common filter patterns, clustering adds overhead without significant benefit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9 (Bonus): COUNT(*) on Materialized Table\n",
    "\n",
    "**Question**: Write a SELECT count(*) query FROM the materialized table you created. How many bytes does it estimate will be read? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNT(*) query\n",
    "result = con.execute(\"\"\"\n",
    "SELECT COUNT(*) as total_count\n",
    "FROM yellow_taxi_materialized\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Count result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: In BigQuery, the estimate would be 0 MB.\n",
    "\n",
    "**Explanation**: BigQuery maintains metadata about tables including the row count. A simple `COUNT(*)` query without any WHERE clause or column references can be answered directly from metadata without scanning any actual data. This is why the estimated bytes is 0 MB - the query doesn't need to read the table data at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Answers\n",
    "\n",
    "1. **Question 1**: 20,332,093 records\n",
    "2. **Question 2**: 0 MB for the External Table and 155.12 MB for the Materialized Table\n",
    "3. **Question 3**: BigQuery is a columnar database - querying two columns requires reading more data than one column\n",
    "4. **Question 4**: 8,333 records with fare_amount = 0\n",
    "5. **Question 5**: Partition by tpep_dropoff_datetime and Cluster on VendorID\n",
    "6. **Question 6**: 310.24 MB for non-partitioned table and 26.84 MB for the partitioned table\n",
    "7. **Question 7**: GCP Bucket\n",
    "8. **Question 8**: False\n",
    "9. **Question 9 (Bonus)**: 0 MB - BigQuery uses metadata for simple COUNT(*) queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Analysis with DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic statistics about the dataset\n",
    "stats = con.execute(\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as total_trips,\n",
    "    COUNT(DISTINCT VendorID) as unique_vendors,\n",
    "    COUNT(DISTINCT PULocationID) as unique_pickup_locations,\n",
    "    COUNT(DISTINCT DOLocationID) as unique_dropoff_locations,\n",
    "    MIN(tpep_pickup_datetime) as earliest_pickup,\n",
    "    MAX(tpep_pickup_datetime) as latest_pickup,\n",
    "    ROUND(AVG(fare_amount), 2) as avg_fare,\n",
    "    ROUND(AVG(trip_distance), 2) as avg_distance\n",
    "FROM yellow_taxi_materialized\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly trip distribution\n",
    "monthly = con.execute(\"\"\"\n",
    "SELECT \n",
    "    EXTRACT(YEAR FROM tpep_pickup_datetime) as year,\n",
    "    EXTRACT(MONTH FROM tpep_pickup_datetime) as month,\n",
    "    COUNT(*) as trip_count,\n",
    "    ROUND(AVG(fare_amount), 2) as avg_fare\n",
    "FROM yellow_taxi_materialized\n",
    "GROUP BY year, month\n",
    "ORDER BY year, month\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Monthly Trip Distribution:\")\n",
    "monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "con.close()\n",
    "print(\"\\nDuckDB connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
